{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# api\n",
    "\n",
    "This is the primary interface to running squ wrappers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas, json, logging\n",
    "from squ.core import *\n",
    "from diskcache import memoize_stampede\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from importlib.resources import path\n",
    "from subprocess import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logger = logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Workspaces\n",
    "\n",
    "The `list_workspaces` function retreives a list of workspaces from blob storage and returns it in various formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours\n",
    "def list_workspaces(fmt: str = \"df\", # df, csv, json, list\n",
    "                    agency: str = \"ALL\"): # Agency alias or ALL\n",
    "    path = datalake_path()\n",
    "    df = pandas.read_csv((path / \"notebooks/lists/SentinelWorkspaces.csv\").open())\n",
    "    df = df.join(pandas.read_csv((path / \"notebooks/lists/SecOps Groups.csv\").open()).set_index(\"Alias\"), on=\"SecOps Group\", rsuffix=\"_secops\")\n",
    "    df = df.rename(columns={\"SecOps Group\": \"alias\", \"Domains and IPs\": \"domains\"})\n",
    "    df = df.dropna(subset=[\"customerId\"]).sort_values(by=\"alias\")\n",
    "    if agency != \"ALL\":\n",
    "        df = df[df[\"alias\"] == agency]\n",
    "    if fmt == \"df\":\n",
    "        return df\n",
    "    elif fmt == \"csv\":\n",
    "        return df.to_csv()\n",
    "    elif fmt == \"json\":\n",
    "        return df.fillna(\"\").to_dict(\"records\")\n",
    "    elif fmt == \"list\":\n",
    "        return list(df[\"customerId\"].unique())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_workspaces().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Analytics Query\n",
    "The below function makes it easy to query all workspaces with sentinel installed using log analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours\n",
    "def list_subscriptions():\n",
    "    return pandas.DataFrame(azcli([\"account\", \"list\"]))[\"id\"].unique()\n",
    "\n",
    "@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours\n",
    "def list_securityinsights():\n",
    "    return pandas.DataFrame(azcli([\n",
    "        \"graph\", \"query\", \"--first\", \"1000\", \"-q\", \n",
    "        \"\"\"\n",
    "        resources\n",
    "        | where type =~ 'microsoft.operationsmanagement/solutions'\n",
    "        | where name startswith 'SecurityInsights'\n",
    "        | project wlid = tolower(tostring(properties.workspaceResourceId))\n",
    "        | join kind=leftouter (\n",
    "            resources | where type =~ 'microsoft.operationalinsights/workspaces' | extend wlid = tolower(id))\n",
    "            on wlid\n",
    "        | extend customerId = properties.customerId\n",
    "        \"\"\"\n",
    "    ])[\"data\"])\n",
    "\n",
    "def loganalytics_query(query):\n",
    "    dfs = []\n",
    "    customerids = list_securityinsights()[\"customerId\"]\n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        futures = [executor.submit(azcli, [\n",
    "            \"monitor\", \"log-analytics\", \"query\",\n",
    "            \"-w\", workspace,\n",
    "            \"--analytics-query\", query\n",
    "        ]) for workspace in customerids]\n",
    "        for future, customerid in zip(futures, customerids):\n",
    "            try:\n",
    "                df = pandas.DataFrame(future.result())\n",
    "            except Exception as e:\n",
    "                logger.warning(e)\n",
    "                continue\n",
    "            else:\n",
    "                if \"TenantId\" not in df.columns:\n",
    "                    df[\"TenantId\"] = customerid\n",
    "                dfs.append(df)\n",
    "    return pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loganalytics_query(\"SecurityIncident | take 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def atlaskit_transformer(inputtext, inputfmt=\"md\", outputfmt=\"wiki\", runtime=\"node\", transformer=path(\"squ\", \"atlaskit-transformer.bundle.js\").absolute()):\n",
    "    return run([runtime, transformer, inputfmt, outputfmt], input=inputtext, text=True, capture_output=True, check=True).stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atlaskit_transformer(\"\"\"# Heading 1\n",
    "\n",
    "- a bullet\n",
    "- [a link](https://github.com)\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
