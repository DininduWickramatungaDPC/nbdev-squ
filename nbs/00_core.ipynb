{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "A set of core functions and a wrapper for the azure cli and some other azure apis, which simplifies authentication and retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import json, subprocess, os, sys, pandas\n",
    "from platformdirs import PlatformDirs\n",
    "from diskcache import Cache, memoize_stampede\n",
    "from tenacity import wait_random_exponential, stop_after_attempt, Retrying\n",
    "from upath import UPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching and retry helpers\n",
    "The below `cache` sets up a persistent per user disk cache (to ensure security) that can be used throughout api setup and configuration. `retryer` will try to run a function again up to 3 times with a random exponential backoff to handle upstream api exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "dirs = PlatformDirs(\"nbdev-squ\")\n",
    "cache = Cache(dirs.user_cache_dir)\n",
    "retryer = Retrying(wait=wait_random_exponential(), stop=stop_after_attempt(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _cli(cmd: list[str], capture_output=True):\n",
    "    cmd = [sys.executable, \"-m\", \"azure.cli\"] + cmd + [\"-o\", \"json\"]\n",
    "    if capture_output: # Try lots, parse output as json\n",
    "        result = retryer(subprocess.run, cmd, capture_output=capture_output, check=True)\n",
    "        return json.loads(result.stdout.decode(\"utf8\"))\n",
    "    else: # Run interactively, ignore success/fail\n",
    "        subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login and secrets management\n",
    "The squ library depends on authentication configured and ready to go. There are 2 paths to login used based on environment variables available. Once logged in it will attempt to populate `cache` with secrets from a configuration keyvault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_config(path = None # Path to read json config into cache from\n",
    "               ):\n",
    "    if path:\n",
    "        return json.loads(path.read_text())\n",
    "    try:\n",
    "        return json.loads(_cli([\"keyvault\", \"secret\", \"show\", \n",
    "                                \"--vault-name\", cache[\"vault_name\"], \n",
    "                                \"--name\", f\"squconfig-{cache['tenant_id']}\"])[\"value\"])\n",
    "    except subprocess.CalledProcessError:\n",
    "        return {}\n",
    "\n",
    "def login(refresh: bool=False # Force relogin\n",
    "         ):\n",
    "    if \"/\" in os.environ.get(\"SQU_CONFIG\", \"\"):\n",
    "        cache[\"vault_name\"], cache[\"tenant_id\"] = os.environ[\"SQU_CONFIG\"].split(\"/\")\n",
    "    if os.environ.get(\"IDENTITY_HEADER\") and not cache.get(\"msi_failed\"):\n",
    "        if refresh: # Forced logout only makes sense for managed service identity (msi) signins\n",
    "            _cli([\"logout\"])\n",
    "        try:\n",
    "            _cli([\"login\", \"--identity\"])\n",
    "        except subprocess.CalledProcessError:\n",
    "            cache[\"msi_failed\"] = True\n",
    "        else:\n",
    "            cache.delete(\"msi_failed\")\n",
    "            cache[\"logged_in\"] = True\n",
    "            cache[\"login_time\"] = pandas.Timestamp(\"now\")\n",
    "    if not os.environ.get(\"IDENTITY_HEADER\") or cache.get(\"msi_failed\"):\n",
    "        while not cache.get(\"logged_in\"):\n",
    "            try:\n",
    "                _cli([\"account\", \"show\"])\n",
    "            except subprocess.CalledProcessError:\n",
    "                tenant = cache.get(\"tenant_id\", [])\n",
    "                if tenant:\n",
    "                    tenant = [\"--tenant\", tenant]\n",
    "                _cli([\"login\", *tenant, \"--use-device-code\"], capture_output=False)\n",
    "            else:\n",
    "                cache[\"logged_in\"] = True\n",
    "                cache[\"login_time\"] = pandas.Timestamp(\"now\")\n",
    "    if cache.get(\"vault_name\"):\n",
    "        for key, value in load_config().items():\n",
    "            cache[key] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to login\n",
    "The login function will be called automatically if the `azcli` function defined below is used and the cache has no login timestamp, otherwise it can be called manually as well to refresh the keyvault config items with `load_config` (this directly loads a keyvault secret into the cache based on the **SQU_CONFIG** environment variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@memoize_stampede(cache, expire=60)\n",
    "def azcli(basecmd: list[str]):\n",
    "    if not cache.get(\"logged_in\"):\n",
    "        login()\n",
    "    return _cli(basecmd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalake Path\n",
    "The `datalake_path` function below, returns a `UPath` pathlib style object pointing to a configured datalake location in the `cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@memoize_stampede(cache, expire=60 * 60 * 24)\n",
    "def datalake_path(expiry_days: int=3, # Number of days until the SAS token expires\n",
    "                  permissions: str=\"racwdlt\" # Permissions to grant on the SAS token\n",
    "                    ):\n",
    "    expiry = pandas.Timestamp(\"now\") + pandas.Timedelta(days=expiry_days)\n",
    "    account = cache[\"datalake_account\"].split(\".\")[0] # Grab the account name, not the full FQDN\n",
    "    sas = azcli([\"storage\", \"container\", \"generate-sas\", \"--auth-mode\", \"login\", \"--as-user\", \n",
    "                 \"--account-name\", account, \"--name\", cache[\"datalake_container\"], \"--permissions\", permissions, \"--expiry\", str(expiry.date())])\n",
    "    return UPath(f\"az://{cache['datalake_container']}\", account_name=account, sas_token=sas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datalake_path()\n",
    "print(\"\\n\".join([str(p) for p in path.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
