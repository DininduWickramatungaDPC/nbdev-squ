# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_api.ipynb.

# %% auto 0
__all__ = ['logger', 'list_workspaces', 'list_subscriptions', 'list_securityinsights', 'loganalytics_query', 'query_all',
           'atlaskit_transformer']

# %% ../nbs/01_api.ipynb 3
import pandas, json, logging
from .core import *
from diskcache import memoize_stampede
from importlib.resources import path
from subprocess import run
from azure.monitor.query import LogsQueryClient, LogsBatchQuery, LogsQueryStatus
from azure.identity import AzureCliCredential

# %% ../nbs/01_api.ipynb 4
logger = logging.basicConfig(level=logging.WARN)

# %% ../nbs/01_api.ipynb 6
@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours
def list_workspaces(fmt: str = "df", # df, csv, json, list
                    agency: str = "ALL"): # Agency alias or ALL
    path = datalake_path()
    df = pandas.read_csv((path / "notebooks/lists/SentinelWorkspaces.csv").open())
    df = df.join(pandas.read_csv((path / "notebooks/lists/SecOps Groups.csv").open()).set_index("Alias"), on="SecOps Group", rsuffix="_secops")
    df = df.rename(columns={"SecOps Group": "alias", "Domains and IPs": "domains"})
    df = df.dropna(subset=["customerId"]).sort_values(by="alias")
    if agency != "ALL":
        df = df[df["alias"] == agency]
    if fmt == "df":
        return df
    elif fmt == "csv":
        return df.to_csv()
    elif fmt == "json":
        return df.fillna("").to_dict("records")
    elif fmt == "list":
        return list(df["customerId"].unique())
    else:
        raise ValueError("Invalid format")

# %% ../nbs/01_api.ipynb 9
@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours
def list_subscriptions():
    return pandas.DataFrame(azcli(["account", "list"]))["id"].unique()

@memoize_stampede(cache, expire=60 * 60 * 3) # cache for 3 hours
def list_securityinsights():
    return pandas.DataFrame(azcli([
        "graph", "query", "--first", "1000", "-q", 
        """
        resources
        | where type =~ 'microsoft.operationsmanagement/solutions'
        | where name startswith 'SecurityInsights'
        | project wlid = tolower(tostring(properties.workspaceResourceId))
        | join kind=leftouter (
            resources | where type =~ 'microsoft.operationalinsights/workspaces' | extend wlid = tolower(id))
            on wlid
        | extend customerId = properties.customerId
        """
    ])["data"])

@memoize_stampede(cache, expire=60 * 5) # cache for 5 mins
def loganalytics_query(query: str, timespan=pandas.Timedelta("14d")):
    client = LogsQueryClient(AzureCliCredential())
    requests = []
    for workspace_id in list_securityinsights()["customerId"]:
        requests.append(LogsBatchQuery(workspace_id=workspace_id, query=query, timespan=timespan))
    results = client.query_batch(requests)
    dfs = []
    for request, result in zip(requests, results):
        if result.status == LogsQueryStatus.PARTIAL:
            for table in result.partial_data:
                df = pandas.DataFrame(table.rows, columns=table.columns)
                df["TenantId"] = request.workspace
                dfs.append(df)
        elif result.status == LogsQueryStatus.SUCCESS:
            table = result.tables[0]
            df = pandas.DataFrame(table.rows, columns=table.columns)
            df["TenantId"] = request.workspace
            dfs.append(df)
        else:
            df = pandas.DataFrame([result.__dict__])
            df["TenantId"] = request.workspace
            dfs.append(df)
    return pandas.concat(dfs)

def query_all(query: str, fmt="df", timespan=pandas.Timedelta("14d")):
    df = loganalytics_query(query, timespan)
    if fmt == "df":
        return df
    elif fmt == "csv":
        return df.to_csv()
    elif fmt == "json":
        return df.fillna("").to_dict("records")
    else:
        raise ValueError("Invalid format")

# %% ../nbs/01_api.ipynb 13
def atlaskit_transformer(inputtext, inputfmt="md", outputfmt="wiki", runtime="node", transformer=path("squ", "atlaskit-transformer.bundle.js").absolute()):
    return run([runtime, transformer, inputfmt, outputfmt], input=inputtext, text=True, capture_output=True, check=True).stdout
